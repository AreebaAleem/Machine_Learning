{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dell XPS White\\Desktop\\New folder\\ML\\Assignment_2\\A2.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dell%20XPS%20White/Desktop/New%20folder/ML/Assignment_2/A2.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dell%20XPS%20White/Desktop/New%20folder/ML/Assignment_2/A2.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dell%20XPS%20White/Desktop/New%20folder/ML/Assignment_2/A2.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dell%20XPS%20White/Desktop/New%20folder/ML/Assignment_2/A2.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dell%20XPS%20White/Desktop/New%20folder/ML/Assignment_2/A2.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "housing_data = pd.read_csv('Housing.csv')\n",
    "features = housing_data.drop('price', axis=1)\n",
    "target = housing_data['price']\n",
    "numeric_features = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
    "categorical_features = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'furnishingstatus']\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "housing_data = pd.read_csv('Housing.csv')\n",
    "features = housing_data.drop('price', axis=1)\n",
    "target = housing_data['price']\n",
    "numeric_features = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
    "categorical_features = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'furnishingstatus']\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "housing_data = pd.read_csv('Housing.csv')\n",
    "features = housing_data.drop('price', axis=1)\n",
    "target = housing_data['price']\n",
    "numeric_features = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
    "categorical_features = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'furnishingstatus']\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "housing_data = pd.read_csv('Housing.csv')\n",
    "features = housing_data.drop('price', axis=1)\n",
    "target = housing_data['price']\n",
    "numeric_features = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
    "categorical_features = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'furnishingstatus']\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "# Transform the training data\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "# without lambda\n",
    "model_no_lambda = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='sigmoid'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model_no_lambda.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history_no_lambda = model_no_lambda.fit(X_train_scaled, y_train, epochs=50, batch_size=16, validation_split=0.2)\n",
    "# Evaluate the model on the test set without lambda\n",
    "loss_no_lambda = model_no_lambda.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Mean Squared Error without Lambda: {loss_no_lambda}\")\n",
    "# with lambda\n",
    "model_lambda = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model_lambda.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model and capture training history\n",
    "history_lambda = model_lambda.fit(X_train_scaled, y_train, epochs=100, batch_size=8, validation_split=0.2)\n",
    "# Evaluate the model on the test set with lambda\n",
    "loss_lambda = model_lambda.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Mean Squared Error with Lambda: {loss_lambda}\")\n",
    "# Multiple Linear Regression without regularization\n",
    "mlr_no_lambda = LinearRegression()\n",
    "mlr_no_lambda.fit(X_train_scaled, y_train)\n",
    "y_pred_mlr_no_lambda = mlr_no_lambda.predict(X_test_scaled)\n",
    "mse_linear_no_lambda = mean_squared_error(y_test, y_pred_mlr_no_lambda)\n",
    "\n",
    "# Multiple Linear Regression with regularization\n",
    "mlr_with_lambda = Ridge(alpha=0.01)\n",
    "mlr_with_lambda.fit(X_train_scaled, y_train)\n",
    "y_pred_mlr_with_lambda = mlr_with_lambda.predict(X_test_scaled)\n",
    "mse_linear_with_lambda = mean_squared_error(y_test, y_pred_mlr_with_lambda)\n",
    "# Compare Mean Squared Errors\n",
    "print(f\"Mean Squared Error without Lambda (ANN): {loss_no_lambda}\")\n",
    "print(f\"Mean Squared Error with Lambda (ANN): {loss_lambda}\")\n",
    "print(f\"Mean Squared Error without Lambda (MLR): {mse_linear_no_lambda}\")\n",
    "print(f\"Mean Squared Error with Lambda (MLR): {mse_linear_with_lambda}\")\n",
    "\n",
    "# Plotting Model Loss (without Lambda)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_no_lambda.history['loss'], label='Training Loss')\n",
    "plt.plot(history_no_lambda.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss (without Lambda)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "# Predict on the test set without lambda\n",
    "y_pred_no_lambda = model_no_lambda.predict(X_test_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_no_lambda)\n",
    "plt.title('Actual vs. Predicted Prices (without Lambda)')\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_lambda.history['loss'], label='Training Loss')\n",
    "plt.plot(history_lambda.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss (with Lambda)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Predict on the test set with lambda\n",
    "y_pred_with_lambda = model_with_lambda.predict(X_test_scaled)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_with_lambda)\n",
    "plt.title('Actual vs. Predicted Prices (with Lambda)')\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Refinements\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "poly_degree = 3\n",
    "poly = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "# Build and train the Polynomial Regression model\n",
    "poly_model = make_pipeline(StandardScaler(), LinearRegression())\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Evaluate the Polynomial Regression model on the test set\n",
    "poly_loss = mean_squared_error(y_test, poly_model.predict(X_test_poly))\n",
    "print(f\"Mean Squared Error for Polynomial Regression: {poly_loss}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_poly = poly_model.predict(X_test_poly)\n",
    "\n",
    "# Plot actual vs. predicted prices for Polynomial Regression\n",
    "plt.scatter(y_test, y_pred_poly)\n",
    "plt.title('Actual vs. Predicted Prices (Polynomial Regression)')\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
